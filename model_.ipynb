{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import math\n",
    "import env\n",
    "import wrangle as w\n",
    "import explore as exp\n",
    "import datetime\n",
    "from scipy.stats import chi2_contingency\n",
    "# Importing necessary libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "app_token = env.app_token\n",
    "year_to_retrieve = '2022'\n",
    "max_req = 2000  # Specify the maximum number of observations to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for 2022 already exists. Loading data from the CSV.\n"
     ]
    }
   ],
   "source": [
    "df = w.wrangle_coll_stage2(year_to_retrieve, app_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48254, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('features_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_datetime</th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>injuries_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_2_category</th>\n",
       "      <th>factors_category_vehicle_1</th>\n",
       "      <th>factors_category_vehicle_2</th>\n",
       "      <th>factors_subcat_vehicle_1</th>\n",
       "      <th>factors_subcat_vehicle_2</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>daylight</th>\n",
       "      <th>daylight_day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 05:17:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>05:17:00</td>\n",
       "      <td>4491857</td>\n",
       "      <td>40.746930</td>\n",
       "      <td>-73.84866</td>\n",
       "      <td>grand central pkwy</td>\n",
       "      <td>queens</td>\n",
       "      <td>11368</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>personal vehicles</td>\n",
       "      <td>driver_related</td>\n",
       "      <td>driver_related</td>\n",
       "      <td>driving violations</td>\n",
       "      <td>driving violations</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>January</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday_Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:30:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>4491344</td>\n",
       "      <td>40.819157</td>\n",
       "      <td>-73.96038</td>\n",
       "      <td>henry hudson parkway</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>10027</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>personal vehicles</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>environmental</td>\n",
       "      <td>environmental</td>\n",
       "      <td>1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>January</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday_Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 16:40:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>16:40:00</td>\n",
       "      <td>4491478</td>\n",
       "      <td>40.806107</td>\n",
       "      <td>-73.91799</td>\n",
       "      <td>saint ann's avenue</td>\n",
       "      <td>bronx</td>\n",
       "      <td>10454</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>personal vehicles</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>environmental</td>\n",
       "      <td>environmental</td>\n",
       "      <td>16</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>January</td>\n",
       "      <td>True</td>\n",
       "      <td>Saturday_Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 02:53:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>02:53:00</td>\n",
       "      <td>4491586</td>\n",
       "      <td>40.646034</td>\n",
       "      <td>-73.99678</td>\n",
       "      <td>40th street</td>\n",
       "      <td>brooklyn</td>\n",
       "      <td>11232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>personal vehicles</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>environmental</td>\n",
       "      <td>environmental</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>January</td>\n",
       "      <td>False</td>\n",
       "      <td>Saturday_Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 17:00:00</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>4491660</td>\n",
       "      <td>40.701195</td>\n",
       "      <td>-73.91409</td>\n",
       "      <td>wyckoff avenue</td>\n",
       "      <td>brooklyn</td>\n",
       "      <td>11237</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>personal vehicles</td>\n",
       "      <td>driver_related</td>\n",
       "      <td>non_driver_related</td>\n",
       "      <td>driving violations</td>\n",
       "      <td>environmental</td>\n",
       "      <td>17</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>January</td>\n",
       "      <td>True</td>\n",
       "      <td>Saturday_Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       crash_datetime crash_date crash_time  collision_id   latitude  \\\n",
       "0 2022-01-01 05:17:00 2022-01-01   05:17:00       4491857  40.746930   \n",
       "1 2022-01-01 01:30:00 2022-01-01   01:30:00       4491344  40.819157   \n",
       "2 2022-01-01 16:40:00 2022-01-01   16:40:00       4491478  40.806107   \n",
       "3 2022-01-01 02:53:00 2022-01-01   02:53:00       4491586  40.646034   \n",
       "4 2022-01-01 17:00:00 2022-01-01   17:00:00       4491660  40.701195   \n",
       "\n",
       "   longitude        on_street_name    borough  zip_code  injuries_count  ...  \\\n",
       "0  -73.84866    grand central pkwy     queens     11368               1  ...   \n",
       "1  -73.96038  henry hudson parkway  manhattan     10027               0  ...   \n",
       "2  -73.91799    saint ann's avenue      bronx     10454               0  ...   \n",
       "3  -73.99678           40th street   brooklyn     11232               0  ...   \n",
       "4  -73.91409        wyckoff avenue   brooklyn     11237               0  ...   \n",
       "\n",
       "   vehicle_2_category  factors_category_vehicle_1  factors_category_vehicle_2  \\\n",
       "0   personal vehicles              driver_related              driver_related   \n",
       "1   personal vehicles          non_driver_related          non_driver_related   \n",
       "2   personal vehicles          non_driver_related          non_driver_related   \n",
       "3   personal vehicles          non_driver_related          non_driver_related   \n",
       "4   personal vehicles              driver_related          non_driver_related   \n",
       "\n",
       "  factors_subcat_vehicle_1 factors_subcat_vehicle_2 hour_of_day day_of_week  \\\n",
       "0       driving violations       driving violations           5    Saturday   \n",
       "1            environmental            environmental           1    Saturday   \n",
       "2            environmental            environmental          16    Saturday   \n",
       "3            environmental            environmental           2    Saturday   \n",
       "4       driving violations            environmental          17    Saturday   \n",
       "\n",
       "     month daylight  daylight_day_of_week  \n",
       "0  January    False        Saturday_Night  \n",
       "1  January    False        Saturday_Night  \n",
       "2  January     True          Saturday_Day  \n",
       "3  January    False        Saturday_Night  \n",
       "4  January     True          Saturday_Day  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48254 entries, 0 to 54203\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   crash_datetime              48254 non-null  datetime64[ns]\n",
      " 1   crash_date                  48254 non-null  datetime64[ns]\n",
      " 2   crash_time                  48254 non-null  object        \n",
      " 3   collision_id                48254 non-null  int64         \n",
      " 4   latitude                    48254 non-null  float64       \n",
      " 5   longitude                   48254 non-null  float64       \n",
      " 6   on_street_name              48254 non-null  object        \n",
      " 7   borough                     48253 non-null  object        \n",
      " 8   zip_code                    48254 non-null  int64         \n",
      " 9   injuries_count              48254 non-null  int64         \n",
      " 10  deaths_count                48254 non-null  int64         \n",
      " 11  injuries                    48254 non-null  bool          \n",
      " 12  deaths                      48254 non-null  bool          \n",
      " 13  vehicle_1_category          48253 non-null  object        \n",
      " 14  vehicle_2_category          48253 non-null  object        \n",
      " 15  factors_category_vehicle_1  48254 non-null  object        \n",
      " 16  factors_category_vehicle_2  48254 non-null  object        \n",
      " 17  factors_subcat_vehicle_1    48254 non-null  object        \n",
      " 18  factors_subcat_vehicle_2    48254 non-null  object        \n",
      " 19  hour_of_day                 48254 non-null  int32         \n",
      " 20  day_of_week                 48254 non-null  object        \n",
      " 21  month                       48254 non-null  object        \n",
      " 22  daylight                    48254 non-null  bool          \n",
      " 23  daylight_day_of_week        48254 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](2), float64(2), int32(1), int64(4), object(12)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33777, 24), (7238, 24), (7239, 24))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the data into train, validation, and test sets with a 70-15-15 ratio\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42, stratify=df['injuries'])\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42, stratify=temp['injuries'])\n",
    "\n",
    "# Checking the shape of the datasets to confirm the split ratio\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33777, 7238, 7239)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.collision_id.nunique(),val.collision_id.nunique(),test.collision_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize DBSCAN\n",
    "dbscan = DBSCAN(eps=0.002, min_samples=15, metric='manhattan')\n",
    "\n",
    "# Prepare the data from the train set and fit the model\n",
    "injury_data_train = train[train['injuries']][['latitude', 'longitude']].values\n",
    "dbscan_labels_train = dbscan.fit_predict(injury_data_train)\n",
    "\n",
    "# Prepare the data from the validation and test sets\n",
    "injury_data_val = val[val['injuries']][['latitude', 'longitude']].values\n",
    "dbscan_labels_val = dbscan.fit_predict(injury_data_val)\n",
    "injury_data_test = test[test['injuries']][['latitude', 'longitude']].values\n",
    "dbscan_labels_test = dbscan.fit_predict(injury_data_test)\n",
    "\n",
    "# Create new DataFrames to hold the cluster labels and unique identifiers\n",
    "train_clusters = train[train['injuries']][['collision_id']].copy()\n",
    "train_clusters['cluster'] = dbscan_labels_train\n",
    "val_clusters = val[val['injuries']][['collision_id']].copy()\n",
    "val_clusters['cluster'] = dbscan_labels_val\n",
    "test_clusters = test[test['injuries']][['collision_id']].copy()\n",
    "test_clusters['cluster'] = dbscan_labels_test\n",
    "\n",
    "# Merge these new DataFrames back into the original train, validation, and test sets\n",
    "train = train.merge(train_clusters, on='collision_id', how='left')\n",
    "val = val.merge(val_clusters, on='collision_id', how='left')\n",
    "test = test.merge(test_clusters, on='collision_id', how='left')\n",
    "\n",
    "# Fill NaN cluster labels with a new cluster label that indicates 'noise' or 'unclassified'\n",
    "noise_label = -1\n",
    "train['cluster'].fillna(noise_label, inplace=True)\n",
    "val['cluster'].fillna(noise_label, inplace=True)\n",
    "test['cluster'].fillna(noise_label, inplace=True)\n",
    "\n",
    "# Convert cluster labels to integers\n",
    "train['cluster'] = train['cluster'].astype(int)\n",
    "val['cluster'] = val['cluster'].astype(int)\n",
    "test['cluster'] = test['cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33777, 26), (7238, 26), (7239, 26))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by cluster label and count the number of injuries in each cluster\n",
    "train_clusters['cluster_injury_count'] = train_clusters.groupby('cluster')['collision_id'].transform('count')\n",
    "\n",
    "# Remove duplicate cluster labels to have a unique set\n",
    "unique_train_clusters = train_clusters.drop_duplicates(subset=['cluster']).copy()\n",
    "\n",
    "# Sort by cluster_injury_count\n",
    "unique_train_clusters = unique_train_clusters.sort_values('cluster_injury_count')\n",
    "\n",
    "# Create a new column cluster_new_name based on the order of the sort\n",
    "unique_train_clusters['cluster_new_name'] = range(len(unique_train_clusters))\n",
    "# Ensure that cluster -1 should remain -1\n",
    "unique_train_clusters.loc[unique_train_clusters['cluster'] == -1, 'cluster_new_name'] = -1\n",
    "\n",
    "# Map the 'cluster_new_name' and 'cluster_injury_count' from 'unique_train_clusters' to the original train, validation, and test sets\n",
    "mapping_new_name = dict(unique_train_clusters[['cluster', 'cluster_new_name']].values)\n",
    "mapping_injury_count = dict(unique_train_clusters[['cluster', 'cluster_injury_count']].values)\n",
    "\n",
    "train['cluster_new_name'] = train['cluster'].map(mapping_new_name)\n",
    "train['cluster_injury_count'] = train['cluster'].map(mapping_injury_count)\n",
    "\n",
    "val['cluster_new_name'] = val['cluster'].map(mapping_new_name)\n",
    "val['cluster_injury_count'] = val['cluster'].map(mapping_injury_count)\n",
    "\n",
    "test['cluster_new_name'] = test['cluster'].map(mapping_new_name)\n",
    "test['cluster_injury_count'] = test['cluster'].map(mapping_injury_count)\n",
    "\n",
    "# Fill NaN values for 'cluster_new_name' and 'cluster_injury_count' with -1 and 0 respectively\n",
    "train['cluster_new_name'].fillna(-1, inplace=True)\n",
    "train['cluster_injury_count'].fillna(0, inplace=True)\n",
    "\n",
    "val['cluster_new_name'].fillna(-1, inplace=True)\n",
    "val['cluster_injury_count'].fillna(0, inplace=True)\n",
    "\n",
    "test['cluster_new_name'].fillna(-1, inplace=True)\n",
    "test['cluster_injury_count'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert the new columns to integer type\n",
    "train['cluster_new_name'] = train['cluster_new_name'].astype(int)\n",
    "train['cluster_injury_count'] = train['cluster_injury_count'].astype(int)\n",
    "\n",
    "val['cluster_new_name'] = val['cluster_new_name'].astype(int)\n",
    "val['cluster_injury_count'] = val['cluster_injury_count'].astype(int)\n",
    "\n",
    "test['cluster_new_name'] = test['cluster_new_name'].astype(int)\n",
    "test['cluster_injury_count'] = test['cluster_injury_count'].astype(int)\n",
    "\n",
    "# Drop the original 'cluster' column and rename 'cluster_new_name' to 'cluster'\n",
    "train.drop(columns=['cluster'], inplace=True)\n",
    "val.drop(columns=['cluster'], inplace=True)\n",
    "test.drop(columns=['cluster'], inplace=True)\n",
    "\n",
    "train.rename(columns={'cluster_new_name': 'cluster'}, inplace=True)\n",
    "val.rename(columns={'cluster_new_name': 'cluster'}, inplace=True)\n",
    "test.rename(columns={'cluster_new_name': 'cluster'}, inplace=True)\n",
    "\n",
    "# Verify if the new features have been correctly added without changing the number of rows\n",
    "train.shape, val.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert 'crash_datetime' to datetime object for train, val, and test sets\n",
    "# train['crash_datetime'] = pd.to_datetime(train['crash_datetime'])\n",
    "# val['crash_datetime'] = pd.to_datetime(val['crash_datetime'])\n",
    "# test['crash_datetime'] = pd.to_datetime(test['crash_datetime'])\n",
    "\n",
    "# Create a reference date (New Year 2022)\n",
    "ref_date = pd.Timestamp('2022-01-01 00:00:00')\n",
    "\n",
    "# Calculate the time since the reference date in days\n",
    "train['time_since_ref_date'] = (train['crash_datetime'] - ref_date).dt.days\n",
    "val['time_since_ref_date'] = (val['crash_datetime'] - ref_date).dt.days\n",
    "test['time_since_ref_date'] = (test['crash_datetime'] - ref_date).dt.days\n",
    "\n",
    "# Drop 'crash_datetime', 'crash_date', 'crash_time'\n",
    "train.drop(['crash_datetime', 'crash_date', 'crash_time'], axis=1, inplace=True)\n",
    "val.drop(['crash_datetime', 'crash_date', 'crash_time'], axis=1, inplace=True)\n",
    "test.drop(['crash_datetime', 'crash_date', 'crash_time'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'crash_datetime', 'crash_date', 'crash_time'\n",
    "train.drop(['injuries_count', 'deaths_count', 'deaths', 'collision_id'], axis=1, inplace=True)\n",
    "val.drop(['injuries_count', 'deaths_count', 'deaths', 'collision_id'], axis=1, inplace=True)\n",
    "test.drop(['injuries_count', 'deaths_count', 'deaths', 'collision_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_columns = train.select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "# numerical_columns = train.drop(columns=['collision_id'], axis=1)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training data\n",
    "train[numerical_columns.columns] = scaler.fit_transform(train[numerical_columns.columns])\n",
    "\n",
    "# Transform the validation and test data using the same scaler\n",
    "val[numerical_columns.columns] = scaler.transform(val[numerical_columns.columns])\n",
    "test[numerical_columns.columns] = scaler.transform(test[numerical_columns.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv('val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_cols = train.drop(columns=['on_street_name']).select_dtypes(include=['object']).columns\n",
    "train_encoded = pd.get_dummies(train, columns=encode_cols)\n",
    "val_encoded = pd.get_dummies(val, columns=encode_cols)\n",
    "test_encoded = pd.get_dummies(test, columns=encode_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                                <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "longitude                               <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "zip_code                                <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "hour_of_day                             <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "daylight                                <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "                                                              ...                        \n",
       "daylight_day_of_week_Thursday_Night     <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "daylight_day_of_week_Tuesday_Day        <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "daylight_day_of_week_Tuesday_Night      <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "daylight_day_of_week_Wednesday_Day      <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "daylight_day_of_week_Wednesday_Night    <scipy.stats._distn_infrastructure.rv_continuo...\n",
       "Length: 80, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features and target variable from the training set\n",
    "# Here, we include both numerical and properly encoded categorical variables\n",
    "X_train = train_encoded.drop(['injuries', 'on_street_name'], axis=1)\n",
    "y_train = train_encoded['injuries']\n",
    "\n",
    "# Initialize SelectKBest with chi2\n",
    "selector_kbest = SelectKBest(score_func=chi2, k=5)\n",
    "\n",
    "# Fit SelectKBest\n",
    "selector_kbest = selector_kbest.fit(X_train, y_train)\n",
    "\n",
    "# Get the scores\n",
    "kbest_scores = pd.Series(selector_kbest.scores_, index=X_train.columns)\n",
    "kbest_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFE</th>\n",
       "      <th>Lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1</td>\n",
       "      <td>0.321981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>1</td>\n",
       "      <td>0.564198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>1</td>\n",
       "      <td>0.656290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour_of_day</th>\n",
       "      <td>2</td>\n",
       "      <td>0.293727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>1</td>\n",
       "      <td>2.645642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_injury_count</th>\n",
       "      <td>1</td>\n",
       "      <td>4.465980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_ref_date</th>\n",
       "      <td>3</td>\n",
       "      <td>0.270305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      RFE     Lasso\n",
       "latitude                1  0.321981\n",
       "longitude               1  0.564198\n",
       "zip_code                1  0.656290\n",
       "hour_of_day             2  0.293727\n",
       "cluster                 1  2.645642\n",
       "cluster_injury_count    1  4.465980\n",
       "time_since_ref_date     3  0.270305"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Extract features and target variable from the training set\n",
    "X_train = train.drop(['injuries'], axis=1).select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "y_train = train['injuries']\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize RFE with Logistic Regression\n",
    "selector_rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "\n",
    "# Fit RFE\n",
    "selector_rfe = selector_rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the ranking of features\n",
    "rfe_ranking = pd.Series(selector_rfe.ranking_, index=X_train.columns)\n",
    "\n",
    "# Initialize and fit Logistic Regression with L1 penalty\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "lasso_importance = pd.Series(np.abs(lasso.coef_[0]), index=X_train.columns)\n",
    "\n",
    "# Combine all feature rankings\n",
    "feature_ranking = pd.DataFrame({\n",
    "    'RFE': rfe_ranking,\n",
    "    # 'SelectKBest': kbest_scores,\n",
    "    'Lasso': lasso_importance\n",
    "})\n",
    "\n",
    "# Display the combined feature rankings\n",
    "feature_ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_injury_count</th>\n",
       "      <th>time_since_ref_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.319235</td>\n",
       "      <td>-0.500001</td>\n",
       "      <td>-0.017709</td>\n",
       "      <td>0.036061</td>\n",
       "      <td>-0.046876</td>\n",
       "      <td>-0.003438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.319235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.007987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>-0.500001</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>-0.002840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour_of_day</th>\n",
       "      <td>-0.017709</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015437</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <td>0.036061</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.015437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.893854</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_injury_count</th>\n",
       "      <td>-0.046876</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>-0.893854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_ref_date</th>\n",
       "      <td>-0.003438</td>\n",
       "      <td>-0.007987</td>\n",
       "      <td>-0.002840</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      latitude  longitude  zip_code  hour_of_day   cluster  \\\n",
       "latitude              1.000000   0.319235 -0.500001    -0.017709  0.036061   \n",
       "longitude             0.319235   1.000000  0.460853    -0.005029  0.015767   \n",
       "zip_code             -0.500001   0.460853  1.000000     0.001821 -0.004246   \n",
       "hour_of_day          -0.017709  -0.005029  0.001821     1.000000 -0.015437   \n",
       "cluster               0.036061   0.015767 -0.004246    -0.015437  1.000000   \n",
       "cluster_injury_count -0.046876  -0.009018  0.015795     0.016362 -0.893854   \n",
       "time_since_ref_date  -0.003438  -0.007987 -0.002840     0.005601  0.001799   \n",
       "\n",
       "                      cluster_injury_count  time_since_ref_date  \n",
       "latitude                         -0.046876            -0.003438  \n",
       "longitude                        -0.009018            -0.007987  \n",
       "zip_code                          0.015795            -0.002840  \n",
       "hour_of_day                       0.016362             0.005601  \n",
       "cluster                          -0.893854             0.001799  \n",
       "cluster_injury_count              1.000000            -0.000624  \n",
       "time_since_ref_date              -0.000624             1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the correlation matrix for the encoded training data\n",
    "train_corr = train.drop(['injuries'], axis=1).select_dtypes(include=['int64', 'int32', 'float64'])\n",
    "# Calculate the correlation matrix for the encoded training data\n",
    "correlation_matrix = train_corr.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "## Modeling\n",
    "\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709595286733576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the baseline accuracy for the 'injuries' column\n",
    "most_frequent_class = train['injuries'].value_counts().idxmax()\n",
    "baseline_accuracy = (train['injuries'] == most_frequent_class).mean()\n",
    "# baseline_accuracy = round(baseline_accuracy * 100, 1)\n",
    "baseline_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily concatenate the train, val, and test datasets\n",
    "temp_df = pd.concat([train, val, test], keys=['train', 'val', 'test'])\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "encode_cols = temp_df.drop(columns=['on_street_name']).select_dtypes(include=['object']).columns\n",
    "temp_df_encoded = pd.get_dummies(temp_df, columns=encode_cols)\n",
    "\n",
    "# Split the data back into train, val, and test sets\n",
    "train_encoded = temp_df_encoded.loc['train']\n",
    "val_encoded = temp_df_encoded.loc['val']\n",
    "test_encoded = temp_df_encoded.loc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709035645205857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Defining the features and the target variable\n",
    "X_train = train_encoded.drop(['injuries'], axis=1).select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "y_train = train_encoded['injuries']\n",
    "X_val = val_encoded.drop(['injuries'], axis=1).select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "y_val = val_encoded['injuries']\n",
    "\n",
    "# Initializing the Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state = 42, max_iter = 500, multi_class= 'multinomial') \n",
    "\n",
    "# Fitting the model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_val_pred = logistic_model.predict(X_val)\n",
    "\n",
    "# Calculating the accuracy of the model\n",
    "logistic_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Displaying the accuracy\n",
    "logistic_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the features and the target variable\n",
    "X_train = train_encoded.drop(['injuries', 'on_street_name'], axis=1)\n",
    "y_train = train_encoded['injuries']\n",
    "X_val = val_encoded.drop(['injuries', 'on_street_name'], axis=1)\n",
    "y_val = val_encoded['injuries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initializing the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Calculating the accuracy of the model on the validation set\n",
    "rf_accuracy = accuracy_score(y_val, y_val_pred_rf)\n",
    "\n",
    "# Rounding the accuracy to keep it concise\n",
    "rf_accuracy = round(rf_accuracy * 100, 1)\n",
    "\n",
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initializing the Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_val_pred_gb = gb_model.predict(X_val)\n",
    "\n",
    "# Calculating the accuracy of the model on the validation set\n",
    "gb_accuracy = accuracy_score(y_val, y_val_pred_gb)\n",
    "\n",
    "# Rounding the accuracy to keep it concise\n",
    "gb_accuracy = round(gb_accuracy * 100, 1)\n",
    "\n",
    "gb_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initializing the Support Vector Machine (SVM) model\n",
    "# Using a linear kernel for simplicity and faster computation\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_val_pred_svm = svm_model.predict(X_val)\n",
    "\n",
    "# Calculating the accuracy of the model on the validation set\n",
    "svm_accuracy = accuracy_score(y_val, y_val_pred_svm)\n",
    "\n",
    "# Rounding the accuracy to keep it concise\n",
    "svm_accuracy = round(svm_accuracy * 100, 1)\n",
    "\n",
    "svm_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Initialize GridSearchCV\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mrf, param_grid\u001b[39m=\u001b[39mparam_grid, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                            cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jongarcia/codeup-data-science/new-york-vehicle-collisions/model_.ipynb#Y230sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_grid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to initialize a new Random Forest Classifier\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate train and validation accuracies\n",
    "rf_train_accuracy = round(accuracy_score(y_train, best_rf.predict(X_train)) * 100, 1)\n",
    "rf_val_accuracy = round(accuracy_score(y_val, best_rf.predict(X_val)) * 100, 1)\n",
    "\n",
    "# Add these accuracies to the results DataFrame\n",
    "new_row = pd.DataFrame({'Model': ['Random Forest (Grid Search)'], 'Train Accuracy (%)': [rf_train_accuracy], 'Validation Accuracy (%)': [rf_val_accuracy]})\n",
    "results_df = pd.concat([results_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_injury_count</th>\n",
       "      <th>time_since_ref_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454685</td>\n",
       "      <td>0.607739</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545631</td>\n",
       "      <td>0.643323</td>\n",
       "      <td>0.931736</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.406593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.365898</td>\n",
       "      <td>0.562323</td>\n",
       "      <td>0.894286</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611606</td>\n",
       "      <td>0.583720</td>\n",
       "      <td>0.872459</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.566074</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33772</th>\n",
       "      <td>0.621443</td>\n",
       "      <td>0.689896</td>\n",
       "      <td>0.930452</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33773</th>\n",
       "      <td>0.384102</td>\n",
       "      <td>0.658432</td>\n",
       "      <td>0.895142</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33774</th>\n",
       "      <td>0.622490</td>\n",
       "      <td>0.683046</td>\n",
       "      <td>0.930452</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33775</th>\n",
       "      <td>0.544284</td>\n",
       "      <td>0.958415</td>\n",
       "      <td>0.942007</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33776</th>\n",
       "      <td>0.777774</td>\n",
       "      <td>0.658330</td>\n",
       "      <td>0.735074</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.379121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33777 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  zip_code  hour_of_day   cluster  \\\n",
       "0      0.454685   0.607739  0.898138     0.608696  0.000000   \n",
       "1      0.545631   0.643323  0.931736     0.739130  0.000000   \n",
       "2      0.365898   0.562323  0.894286     0.956522  0.000000   \n",
       "3      0.611606   0.583720  0.872459     0.913043  0.000000   \n",
       "4      0.566074   0.622016  0.931522     0.565217  0.000000   \n",
       "...         ...        ...       ...          ...       ...   \n",
       "33772  0.621443   0.689896  0.930452     0.826087  0.000000   \n",
       "33773  0.384102   0.658432  0.895142     0.043478  0.000000   \n",
       "33774  0.622490   0.683046  0.930452     0.130435  0.000000   \n",
       "33775  0.544284   0.958415  0.942007     0.608696  0.000000   \n",
       "33776  0.777774   0.658330  0.735074     0.826087  0.947368   \n",
       "\n",
       "       cluster_injury_count  time_since_ref_date  \n",
       "0                  1.000000             0.708791  \n",
       "1                  1.000000             0.406593  \n",
       "2                  1.000000             0.958791  \n",
       "3                  1.000000             0.645604  \n",
       "4                  1.000000             0.914835  \n",
       "...                     ...                  ...  \n",
       "33772              1.000000             0.799451  \n",
       "33773              1.000000             0.766484  \n",
       "33774              1.000000             0.593407  \n",
       "33775              1.000000             0.107143  \n",
       "33776              0.001212             0.379121  \n",
       "\n",
       "[33777 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
